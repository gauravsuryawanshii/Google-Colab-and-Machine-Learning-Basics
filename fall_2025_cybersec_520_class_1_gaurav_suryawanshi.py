# -*- coding: utf-8 -*-
"""Fall_2025_CYBERSEC_520_Class_1_Gaurav_Suryawanshi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KB3bWoc0H7-HRGYhSlPrmPV0doXS43yZ

# CYBERSEC 520
# Class 1: Introduction to Machine Learning Models

#Prerequisites

This course does not presume or require any prior knowledge in machine learning.

However, to be successful in the class you should be familiar with variables, linear equations, graphs of functions, histograms, and statistical means.

You should have some familiarty with Python because the assignments and projects are in Python. If you are expereienced in other programming languages (Java, C++, Rust, etc.) you shoudl be able to easily pick up the Python needed for this course.

The following links may be helpful for a refresher.

### Algebra
* Basics such as [variables](https://www.khanacademy.org/math/algebra/x2f8bb11595b61c86:foundation-algebra/x2f8bb11595b61c86:intro-variables/v/what-is-a-variable), [coefficients](https://www.khanacademy.org/math/cc-sixth-grade-math/cc-6th-equivalent-exp/cc-6th-parts-of-expressions/v/expression-terms-factors-and-coefficients), and [functions](https://www.khanacademy.org/math/algebra-home/alg-functions)
* [linear equations](https://wikipedia.org/wiki/Linear_equation)
* [logarithms](https://wikipedia.org/wiki/Logarithm), and logarithmic equations.


### Statistics
* [mean, median, and outliers](https://www.khanacademy.org/math/probability/data-distributions-a1/summarizing-center-distributions/v/mean-median-and-mode)
* [standard deviation](https://wikipedia.org/wiki/Standard_deviation)
* [histograms](https://wikipedia.org/wiki/Histogram)


### Python Programming
* For a Refresher on Python you can use the [Python Tutorial](https://docs.python.org/3/tutorial/)
* Another good resource is: [Python for Data Analysis, 3rd Edition](https://wesmckinney.com/book/python-basics.html) Specifically Chapters 1-5,7 and 9
* Colab waltkthrough on [NumPy](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/numpy_ultraquick_tutorial.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=mlcc-prework&hl=en)
* Colab walkthrough on [Pandas](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=mlcc-prework&hl=en)

## Nice to have

Familiarity here helps but concepts will be introduced and covered as needed. I'll add in some links

### Linear Algrebra
* tensors
* matrix multiplcation

###  Trigonometry
* Tanh - used as an activation function in Neural networks

### Calculus (don't worry it won't be tested)
* concept of a derivative (you won't have to actually calculate derivatives)
* gradient or slope
* partial derivatives
* chain rule

# Notebook Setup
"""

# Google Colab only:  mount your drive to access your data files.

from google.colab import drive
drive.mount('/content/drive')

"""Calling in some additional libraries"""

# This installs
!pip install umap-learn[plot]
#!pip install holoviews
#!pip install -U ipykernel

# Commented out IPython magic to ensure Python compatibility.
# import the libraries.
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
# %matplotlib inline

"""### Numpy

NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.
[https://numpy.org/](https://numpy.org/)

### Matplotlib
Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. [https://matplotlib.org/](https://matplotlib.org/)

### seaborn
Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.
[https://seaborn.pydata.org/](https://seaborn.pydata.org/)

### pandas

pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. [https://pandas.pydata.org/](https://pandas.pydata.org/)

### Scikit Learn
Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. [https://scikit-learn.org/](https://scikit-learn.org/)
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import umap
reducer = umap.UMAP()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style to a more visually appealing preset
#plt.style.use('seaborn')

# Further customize the style
plt.rcParams.update({
    'figure.figsize': (10, 6),
    'axes.facecolor': '#f0f0f0',
    'axes.edgecolor': '#333333',
    'axes.labelcolor': '#333333',
    'figure.facecolor': 'white',
    'grid.color': '#888888',
    'grid.linestyle': ':',
    'text.color': '#333333',
    'xtick.color': '#333333',
    'ytick.color': '#333333',
    'xtick.direction': 'out',
    'ytick.direction': 'out',
    'lines.linewidth': 2,
    'font.family': 'sans-serif',
    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif'],
})

# Set a color palette
sns.set_palette("deep")

print("Matplotlib style has been set for all subsequent plots.")

"""# Machine Learning at its most simple

## It starts with Data
"""

# Generate sample data
np.random.seed(42)

# We want the y values to be correlated to the X but with some variation
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = 2 * X + 1 + np.random.randn(100, 1) * 2


# Plot the results
plt.figure(figsize=(12, 6))
plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')

#Label the Plot
plt.xlabel('X')
plt.ylabel('y')
plt.title('Sample Data')

#Display the plot
plt.show()

"""## Then you need an outcome

What do you want to achieve? What is the end goal? In regression we may want to predict something.
"""

from ipywidgets import interactive, FloatSlider

def plot_regression_line(slope, intercept):
    # Clear previous plot
    plt.clf()

    # Plot data points
    plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')

    # Plot regression line
    y_pred = slope * X + intercept
    plt.plot(X, y_pred, color='red', label='Regression line')

    # Set labels and title
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('Interactive Linear Regression')

    # Show plot
    plt.show()

# Create interactive plot
interactive_plot = interactive(plot_regression_line,
                               slope=FloatSlider(min=-5, max=5, step=0.05, value=0),
                               intercept=FloatSlider(min=-10, max=10, step=0.05, value=0))

# Display the interactive plot
display(interactive_plot)

"""## But how do we know that is a good fit?
We need a metric for how well we fit it.

## The Loss Function or Error Function

One of the most common in Regression Problems is the

MEAN SQUARED ERROR :

## $$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

MSE:

* Heavily penalizes large errors
* Sensitive to outliers
* Commonly used in linear regression item

### Lets go back to our visualization
"""

# Let's modify our function

def plot_regression_line(slope, intercept):
    # Clear previous plot
    plt.clf()

    # Plot data points
    plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')

    # Plot regression line
    y_pred = slope * X + intercept
    plt.plot(X, y_pred, color='red', label='Regression line')

## Added in the calculation and display for MSE

    # Calculate and display MSE
    mse = mean_squared_error(y, y_pred)
    plt.text(0.05, 0.95, f'MSE = {mse:.2f}', transform=plt.gca().transAxes,
             fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # Plot prediction errors
    for i in range(len(X)):
        plt.plot([X[i], X[i]], [y[i], y_pred[i]], 'g-', alpha=0.3)

    # Set labels and title
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title('Interactive Linear Regression')

    # Show plot
    plt.show()

# Create interactive plot
interactive_plot = interactive(plot_regression_line,
                               slope=FloatSlider(min=-5, max=5, step=0.05, value=0),
                               intercept=FloatSlider(min=-10, max=10, step=0.05, value=0))

# Display the interactive plot
display(interactive_plot)

"""## Let the Machine "Learn" From Data

"""

# Model Creation and Training

# Create and train the model

model = LinearRegression() #select a model
model.fit(X, y) # fit it to your data

# Make predictions
y_pred = model.predict(X)


# Visualization (Code cell)
plt.figure(figsize=(12, 6))

# Data points
plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')

# Regression line
plt.plot(X, y_pred, color='red', label='Linear Regression')

# Labels and title
plt.xlabel('X')
plt.ylabel('y')
plt.title('Simple Linear Regression')
plt.legend()
plt.show()

mse = mean_squared_error(y, y_pred)

# Calculate Mean Squared Error
mse = mean_squared_error(y, y_pred)

# Results
print(f"Coefficient (slope): {model.coef_[0][0]:.2f}")
print(f"Intercept: {model.intercept_[0]:.2f}")
print(f"Mean Squared Error (Loss): {mse:.2f}")

# Add outlier
outlier_x, outlier_y = 9.5, 0.2
X = np.append(X, outlier_x)
y = np.append(y, outlier_y)

# Reshape X to be 2D (needed by sklearn)
X = X.reshape(-1, 1)

# Refit the model
model.fit(X, y) # fit it to your data

# Make predictions
y_pred = model.predict(X)

# Visualization (Code cell)
plt.figure(figsize=(12, 6))

# Data points
plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')

# Regression line
plt.plot(X, y_pred, color='red', label='Linear Regression')

# Calculate and display MSE
mse = mean_squared_error(y, y_pred)
plt.text(0.05, 0.95, f'MSE = {mse:.2f}', transform=plt.gca().transAxes,
             fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))


# Labels and title
plt.xlabel('X')
plt.ylabel('y')
plt.title('Simple Linear Regression')
plt.legend(loc='upper center')
plt.show()

"""# Getting Data

## Data Locations

You can get your data from your google drive, or pull directly from a link
"""

# Google Colab:  mount your drive to access your data files.

from google.colab import drive
drive.mount('/content/drive')

"""## Sample Data set

Simple, common intro multi-classification dataset.
"""

penguins = pd.read_csv("https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv")
#examine first 5 rows
penguins.head()

"""# Process (Will cover this more in-depth next Class)

![Time](https://miro.medium.com/v2/resize:fit:720/format:webp/1*cn6hbAI-TFnNnJBTcNhumA.png)

We are going to go into data exploration next lecture.  But for today we need to clean up any missing values and look at the dataset
"""

#First we want get rid of bad data
penguins = penguins.dropna()
penguins.species_short.value_counts()

"""## Splitting the Data

Today we are only going to look at numerical features. First we are going to drop the categorical variables and split the data into independent (X) and dependent (y) variables.
"""

# drop the categorical variables -- we will talk about how to process them next class
X_penguins = penguins.drop(['island', 'sex', 'species_short'], axis=1)
y_penguins = penguins['species_short']

# visualize to make sure we did it correctly
X_penguins.head()

"""## Split the data into Train and Test.

![overfitting](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)

[Source](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/)

Fortunately sklearn does this automatically using either an 80/20 or 75/25 train/test split. These values can be modified, But, we are going to stick with the defaults here.

*Note: Random state is used here for repeatability.  Defaults pull a random INT to initialize the state. This is good to keep in mind if you want people to help you troubleshoot so they can replicate what you have done*
"""

from sklearn.model_selection import train_test_split
Xtrain, Xtest, ytrain, ytest = train_test_split(X_penguins, y_penguins,
                                                random_state=777)
print(Xtrain.shape)
print(Xtest.shape)
print(ytrain.shape)
print(ytest.shape)

print(Xtrain.head())
print(ytrain.head())

"""# Train the model

First we need to select a model.  Initially we will use K Nearest Neighbors or kNN is one of the simplest and most used classification algorithms.

kNN stores all available cases and classifies new cases based on a similarity measure (eg distance function).

![knn](https://miro.medium.com/v2/resize:fit:720/0*ItVKiyx2F3ZU8zV5)

[source](https://www.kdnuggets.com/2020/11/most-popular-distance-metrics-knn.html)

### Let's train the model

# Rationale behind the code - "Tried all the necessary values from 5-10, it was overfitting and hence we came up to the value of 8, with Sejal (group member)"
"""

# Import necessary libraries
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Scale the features: fit on train, transform both train and test
scaler = StandardScaler()
Xtrain_scaled = scaler.fit_transform(Xtrain)
Xtest_scaled = scaler.transform(Xtest)

# Set model hyperparameters with weights added
model = KNeighborsClassifier(n_neighbors=8, metric='manhattan', weights='distance')

# Fit the model on scaled training data
model.fit(Xtrain_scaled, ytrain)

# Predict on scaled test data
y_model = model.predict(Xtest_scaled)

# Calculate and print accuracy
acc = accuracy_score(ytest, y_model)
print(f"Accuracy: {acc:.3f}")

"""### Enter hyperparameters

#### Question: What is a a **hyperparameter**?

In machine learning, a hyperparameter is a parameter whose value is used to **control the learning process**.

The choice of Hyperparaeters will determine the values of **model parameters**, for example, the weights, biases, etc.,that a ML algorithm ends up learning

Example:

We can change From Euclidean

$d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}$

to Manhattan

$d(p, q) = \sum_{i=1}^{n} |p_i - q_i|$
"""

from matplotlib.widgets import Slider
from IPython.display import display

def create_distance_visualization():
    # Set up the figure and axis
    fig, ax = plt.subplots(figsize=(10, 8))
    plt.subplots_adjust(bottom=0.3)
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 10)
    ax.set_aspect('equal', adjustable='box')

    # Initial points
    point1 = [2, 2]
    point2 = [8, 8]

    # Plot points and lines
    scatter = ax.scatter(point1[0], point1[1], color='red', s=100, label='Point 1')
    scatter2 = ax.scatter(point2[0], point2[1], color='blue', s=100, label='Point 2')
    manhattan_line, = ax.plot([], [], 'r--', lw=2, label='Manhattan')
    euclidean_line, = ax.plot([], [], 'b-', lw=2, label='Euclidean')

    # Add legend
    ax.legend()

    # Function to update the plot
    def update(val):
        x1, y1 = x1_slider.val, y1_slider.val
        x2, y2 = x2_slider.val, y2_slider.val

        scatter.set_offsets([x1, y1])
        scatter2.set_offsets([x2, y2])

        manhattan_line.set_data([x1, x1, x2], [y1, y2, y2])
        euclidean_line.set_data([x1, x2], [y1, y2])

        manhattan_dist = abs(x2 - x1) + abs(y2 - y1)
        euclidean_dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)

        ax.set_title(f'Manhattan Distance: {manhattan_dist:.2f}, Euclidean Distance: {euclidean_dist:.2f}')

        fig.canvas.draw_idle()

    # Create sliders
    ax_x1 = plt.axes([0.1, 0.2, 0.8, 0.03])
    ax_y1 = plt.axes([0.1, 0.15, 0.8, 0.03])
    ax_x2 = plt.axes([0.1, 0.1, 0.8, 0.03])
    ax_y2 = plt.axes([0.1, 0.05, 0.8, 0.03])

    x1_slider = Slider(ax_x1, 'X1', 0, 10, valinit=point1[0])
    y1_slider = Slider(ax_y1, 'Y1', 0, 10, valinit=point1[1])
    x2_slider = Slider(ax_x2, 'X2', 0, 10, valinit=point2[0])
    y2_slider = Slider(ax_y2, 'Y2', 0, 10, valinit=point2[1])

    # Connect update function to sliders
    x1_slider.on_changed(update)
    y1_slider.on_changed(update)
    x2_slider.on_changed(update)
    y2_slider.on_changed(update)

    # Initial update
    update(None)

    # Display the plot
    plt.show()

# Create and display the visualization
create_distance_visualization()

"""## So what does that look like for knn?  """

# Importing necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from matplotlib.animation import FuncAnimation
from IPython.display import HTML

# Generate sample data
np.random.seed(0)
X = np.random.rand(100, 2)
y = (X[:, 0] + X[:, 1] > 1).astype(int)

# Create a mesh grid
x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

# Function to plot the decision boundary
def plot_decision_boundary(clf, ax):
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    ax.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)
    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolor='black')
    ax.set_xlabel('Feature 1')
    ax.set_ylabel('Feature 2')
    ax.set_title(f'k-NN (k={clf.n_neighbors})')

# Create the animation
fig, ax = plt.subplots(figsize=(10, 8))

def animate(k):
    ax.clear()
    clf = KNeighborsClassifier(n_neighbors=k)
    clf.fit(X, y)
    plot_decision_boundary(clf, ax)

anim = FuncAnimation(fig, animate, frames=range(1, 21), interval=500, repeat=True)

# Close the static figure to prevent it from displaying
plt.close(fig)

# Display the animation in the notebook
HTML(anim.to_jshtml())

#number of neighbors, type of weighting and the type of algorithm are all examples of hyperparameters.
model = KNeighborsClassifier(n_neighbors=8, weights='distance', metric='manhattan',algorithm='brute')

#retraining the model
model.fit(Xtrain, ytrain)
y_model = model.predict(Xtest)
accuracy_score(ytest, y_model)

"""There we go. 3 slight tweaks to the hyperparameter settings improves the model perfromance by nearly 5 percentage points.  Or more importantly, especially for a cyber context, a 20% reduction in the error rate.

*To add to the confusion, the documentation for the models ([such as KNN](hhttps://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) often uses the term parameters to describe the hyperparamteters for the model*

### Effect of scaling data
"""

X_penguins.head()

"""Until now, **Unscaled data**.  Scaling, or **Normalization** transforms features to be on a similar scale which improves the performance and training stability of the model.


If you are measuring distance and paramaters have different scales, the larger-scaled parameters will dominate the calculation.
"""

#Scale the data
scaled_penguin_data = StandardScaler().fit_transform(X_penguins)
scaled_penguin_data[:5]

"""Let's visualize the effect.

It is hard to visualize multi-dimensional data. So we will first use a dimensionality reduction technique called UMAP -- there are many other ones as well. Which will reduce the higher dimensional data into 2-dimensions.

Then we will plot the results and use the species' short name to color code the results.
"""

#UMAP projection (2-D mapping)
embedding = reducer.fit_transform(X_penguins)
embedding_scaled = reducer.fit_transform(scaled_penguin_data)

#plotting

# Not necessary, but sets the aspect ration at 4:3 which is nice for graph visualization
sns.set(style='white', context='notebook', rc={'figure.figsize':(12,9)})

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# Display the plots
#Raw Data
ax1.scatter(
    embedding[:, 0],
    embedding[:, 1],
    #Maps the color to each of the species.  We will use this mapping more.
    c=[sns.color_palette()[x] for x in penguins.species_short.map({"Adelie":0, "Chinstrap":1, "Gentoo":2})])
ax1.set_title(label='Raw Data')

#scaled Data
ax2.scatter(
    embedding_scaled[:, 0],
    embedding_scaled[:, 1],
    #Maps the color to each of the species.  We will use this mapping more.
    c=[sns.color_palette()[x] for x in penguins.species_short.map({"Adelie":0, "Chinstrap":1, "Gentoo":2})])
ax2.set_title('Scaled Data')

# Adjust spacing between plots
plt.tight_layout()

# Display the plot
plt.show()

"""You can see some good separation of points in the embedding plot.  But, there is some overlap of points.  Typically what you would do here is go in and look at some of the individual points to see if there is something abnormal in the data (mislabeled, decimal point error, etc.).  But, we are going to skip that.

To learn more about UMAP:  Read [The Docs](https://umap-learn.readthedocs.io/en/latest/) or [The Paper](https://arxiv.org/abs/1802.03426)

---
"""

#you can use the make_pipeline function to combine the model and scaler used.
from sklearn.pipeline import make_pipeline
clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))

clf.fit(Xtrain, ytrain)
y_model = clf.predict(Xtest)
accuracy_score(ytest, y_model)

"""[link text](https://)98.8% Acuracy and that includes lumping together male and female penguins

## Let's Visualize this

Here we are going to **take 2** columns from the **Penguins** data that we will use for visualization.
"""

#import decision region plotting
from mlxtend.plotting import plot_decision_regions
data = penguins[["culmen_length_mm","flipper_length_mm", "species_short"]]
sns.pairplot(data, hue='species_short', height=4, aspect=1.5)

X_penguins = penguins[["culmen_length_mm","flipper_length_mm"]]
y_penguins = penguins['species_short']

#getting codes
species = pd.Categorical(y_penguins).codes
Xtrain, Xtest, ytrain, ytest = train_test_split(X_penguins, species,
                                               random_state=1)

# clf is short for classifier - call this whatever you want.
clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=4, weights= 'distance', algorithm='brute'))

#train the data
clf.fit(Xtrain, ytrain)

# plot all of the data using the decision regions.
plot_decision_regions(X_penguins.values, species, clf=clf, legend=2)

y_model = clf.predict(Xtest)
accuracy_score(ytest, y_model)

"""# Cyber Example

The class today uses data from the [Intrusion Detection Evaluation Dataset (CICIDS2017)](https://www.unb.ca/cic/datasets/ids-2017.html)

- The CICIDS2017 dataset contains benign and the most up-to-date (__as of 2017__) common attacks, which resembles the true real-world data (PCAPs).

- The `.csv` files used from this analysis were generated from from network traffic analysis using [CICFlowMeter](http://www.netflowmeter.ca/netflowmeter.html) feature extraction tools - Also see the [GitHub](https://github.com/ahlashkari/CICFlowMeter) repository.
  - Labeled flows based on the time stamp, source, and destination IPs, source and destination ports, protocols and attack (CSV files).

Newer datasets are available from the [Canadian Institute for Cybersecurity datasets](https://www.unb.ca/cic/datasets/index.html). They include:
- [Android Malware dataset (InvesAndMal2019)](https://www.unb.ca/cic/datasets/invesandmal2019.html)
- [DDoS dataset (CICDDoS2019)](https://www.unb.ca/cic/datasets/ddos-2019.html)
-  [IPS/IDS dataset on AWS (CSE-CIC-IDS2018)](https://www.unb.ca/cic/datasets/ids-2018.html)

A websearch will also turn up many other datasets that can be used.
"""

# I have already downloaded the DDoS dataset to my drive
ddos = pd.read_csv('/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')
ddos.head(100)

from matplotlib import pyplot as plt
ddos[' Flow Duration'].plot(kind='hist', bins=20, title=' Flow Duration')
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
ddos[' Destination Port'].plot(kind='hist', bins=20, title=' Destination Port')
plt.gca().spines[['top', 'right',]].set_visible(False)

list(ddos)

"""Let's make sure to remove bad data -- so get rid of any infinite (`inf` or `-inf`) or missing (`NaN`) values"""

ddos.replace([np.inf, -np.inf], np.nan, inplace=True)
ddos = ddos.dropna()
ddos[' Label'].value_counts()

"""### Let's subsample the data set so that we can better visualize it."""

n = len(ddos)
idx = np.random.permutation(range(n))[:2000] #selects a random permutation of samples up to the number you want.
l = len(idx)
idx.sort()
small_ddos = ddos.iloc[idx[:l]]
small_ddos[' Label'].value_counts()

"""A good thing to keep in mind is that more data is often better for model performance and improving transferability of the models.  But, it is **not** always good for initial data exploration.

### Now let's visualize the data
"""

#Create a new dataframe for exploration

# This is using all of the categories.
df1 = small_ddos.copy()

#y values
df2 = df1[' Label'].copy()

#remove label collumn from x values
df1.drop(columns=[' Label'], inplace=True)

#scaled data
scaled_ddos = StandardScaler().fit_transform(df1)

#Create the embeddings for visualization
embedding2 = reducer.fit_transform(scaled_ddos)
embedding2.shape

#plot the data
plt.scatter(
    embedding2[:, 0],
    embedding2[:, 1],
    ## Labels are not in the np array so we need to color code the values
    c=[sns.color_palette()[x] for x in df2.map({"BENIGN":0, "DDoS":1})])
plt.gca().set_aspect('equal', 'datalim')
plt.title('UMAP projection of the CIC 2017 dataset', fontsize=24)

"""So this is a good candidate for a classification problem."""

#Let's take 2 features.
ddos_subset =  small_ddos[[ ' Fwd Packet Length Mean',
                     ' Flow Duration',
                      ' Label']].copy()
ddos_subset.head()

dfx = ddos_subset.drop(' Label', axis=1)
dfy = ddos_subset[' Label']
Xtrain, Xtest, ytrain, ytest = train_test_split(dfx, dfy,
                                                random_state=1)

clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))
clf.fit(Xtrain, ytrain)
y_model = clf.predict(Xtest)
accuracy_score(ytest, y_model)

"""Now you have a ML model that detects DDoS attacks with **96.4% accuracy**.

# Machine Learning Metrics

Accuracy is the ratio of the correct predictions to incorrect predictions. Accuracy is an easy metric to intuitively grasp. But it is not always the **Best** one to use in Machine Learning.

What do we care about in Cyber? False Positives and Missed Events.

If a malicious event is only 1 out 10,000 events,  a simple classifier that marks everything as benign will achieve an accuracy of 99.99%

What other ways can we look at model performance?

Let's print out the classification report.
"""

from sklearn.metrics import classification_report
print(classification_report(ytest, y_model))

"""![1_OhEnS-T54Cz0YSTl_c3Dwg.jpeg](data:image/jpeg;base64,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)

$precission = \frac{True Positive}{True Positive + False Positive}$

A higher number here means that you model does a good job of minimizing false positive rate.

$recall = \frac{True Positive}{True Positive + False Negative}$

In the context of cyber, A higher score here will indicate how well your model does at catching all malicious behavior.

### We can plot the actual values in each bucket
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(ytest, y_model)
cm_display = ConfusionMatrixDisplay(cm).plot()

"""Here zero is Benign and 1 is DDoS, so with this very limited dataset, we have 5 missed attacks and 17 false positives.

### Balance between Precision and Recall:

* Useful for Imbalanced Datasets (example fraud detection)
* Single Metric for Model Comparison
* Indication of Model Robustness

$F_1 = 2*\frac{Precision*Recall}{Precision+Recall}$


F1 Score is the harmonic mean between precision and recall.

F1 is typically used in machine learning when you want to balance Precision and Recall **AND** there is an uneven class distribution.

In some of the other data sets we will come across, there is not so cleanly a split.


There are other weighting scores, F2, F1.5, etc. that are less common but can be used when you want to weight recall hihger ($\beta >1)$ or precision higher ($\beta <1)$

$F_\beta = (1+\beta^2)*\frac{Precision*Recall}{(\beta^2 *Precision)+Recall}$
"""

from sklearn.metrics import f1_score
#f1_score(ytest, y_model)
f1_score(ytest, y_model, average='weighted')

"""KNN requires a LOT of human preprocessing and selction to perform well.

KNN is purely a distance measurement calculation.  So it is only looking calculating distance.  If we include parameters where measurements overlap (i.e. they are **close** to each other, then model performance will deteriorate.

## Reciever Operator Characteristic (ROC)
Visualizing model performance.  Shows the tradeoff between different thresholds in a binary classification. i.e. Benign vs DDoS.

Plots FPR vs. TPR.  The Area under the ROC Curve (AUC) is a single metric, like F1 score that can be used to compare performance.

* AUC = 1.0 -- Perfect Classifier
* AUC = 0.5 -- Random Guessing

Purposes:

* Threshold Selection:
* Model Comparison
* Imbalanced Datasets
"""

from sklearn.metrics import roc_curve, auc

y_prob = clf.predict_proba(Xtest)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(ytest, y_prob, pos_label='DDoS')
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""# Support Vector Machines (SVMs)

"""

from sklearn import datasets
from sklearn.svm import SVC

# Generate a toy dataset (2D for visualization)
X, y = datasets.make_blobs(n_samples=100, centers=2)

# Create the scatter plot
plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)

plt.show()

"""![SVM](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*06GSco3ItM3gwW2scY6Tmg.png)

[*source*](https://towardsdatascience.com/support-vector-machine-vs-logistic-regression-94cc2975433f)
"""

# Train an SVM
clf = SVC(kernel='linear', C=1)
clf.fit(X, y)

# Create the scatter plot
plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)


# Plot the decision boundary
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# Create grid to evaluate model
xx = np.linspace(xlim[0], xlim[1], 30)
yy = np.linspace(ylim[0], ylim[1], 30)
YY, XX = np.meshgrid(yy, xx)
xy = np.vstack([XX.ravel(), YY.ravel()]).T
Z = clf.decision_function(xy).reshape(XX.shape)

# Plot decision boundary and margins
ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,
           linestyles=['--', '-', '--'])
# Highlight the support vectors with a circle around them
ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,
           facecolors='none', edgecolors='k')

# Highlight the support vectors with a circle around them
ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,
           facecolors='none', edgecolors='k')

plt.show()

"""## In SVM

we try to balance the margin distance with the number of correct classifications.

Hinge loss penalizes misclassification the further from the boundary and can be visualized here.

![image](https://cdn.hackernoon.com/images/wfOhdkoK2Ng95bY7s4ahmT5sb9N2-0wg3o8l.png)


IN SVM we try to minimize the objective function:

$J(w) = \frac{1}{2} ||w||^2 + C \sum_{i=1}^{N} \max(0, 1 - y_i(w \cdot x_i + b))$

THe margin is given as

$\text{margin} = \frac{2}{||w||}$

We can manipulate the tradeoff between the boundary width and the classification accuracy by modifying the $C$ parameter or Cost coefficient
The higher $C$, the higher the importance on classification.

### What if your dataset looks like this?
"""

# Generate a toy dataset (2D for visualization)
X, y = datasets.make_moons(n_samples=200, noise=0.2)

# Create the scatter plot
plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)

plt.show()

"""### What is kernel function?

SVM algorithms use a set of mathematical functions that are defined as the kernel.

The job of the kernel is to transform input data. For linearly seperable data, we will use a linear kernel:

But for non-linearly seperable data, we will typically use a Radial Basis Function (RBF)

Example transformation:

![RPF](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nR_sMAK1OECelJd-TF_4Q.png)


An RBF is a functin whose value depends only on the distance between the input and some fixed point

$K(\mathbf{x}, \mathbf{z}) = \exp\left(-\gamma \|\mathbf{x} - \mathbf{z}\|^2\right)$


Here $\gamma$ defines how far the influence of a single training example reaches, with low values meaning far and high values meaning close


THere are other kernel functions but we wont get into them here.
"""

# Generate a dataset with overlapping classes
X, y = datasets.make_moons(n_samples=200, noise=0.2, random_state=0)

# Define a function to plot decision boundary
def plot_decision_boundary(clf, X, y, ax):
    # Create the scatter plot
    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)

    # Plot the decision boundary
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    # Create grid to evaluate model
    xx = np.linspace(xlim[0], xlim[1], 30)
    yy = np.linspace(ylim[0], ylim[1], 30)
    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T
    Z = clf.decision_function(xy).reshape(XX.shape)

    # Plot decision boundary and margins
    ax.contourf(XX, YY, Z, levels=np.arange(-1, 1.1, 0.1), cmap=plt.cm.RdBu, alpha=0.8)
    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])

    # Highlight the support vectors with a circle around them
    ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100, facecolors='none', edgecolors='k')


# Different values of C
C_values = [0.01, 1, 100]
models = []

# Train SVMs with different C values
for C in C_values:
    clf = SVC(kernel='rbf', C=C, gamma='auto')
    clf.fit(X, y)
    models.append(clf)

# Plot each model's decision boundaries side by side
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for ax, model, C in zip(axes, models, C_values):
    plot_decision_boundary(model, X, y, ax)
    ax.set_title(f"C = {C}")

plt.tight_layout()
plt.show()

"""### So how does that work on the Cyber data set?

Let's use the same subset of the data.
"""

dfx = dfx = ddos_subset.drop(' Label', axis=1)
dfy = ddos_subset[' Label']
Xtrain, Xtest, ytrain, ytest = train_test_split(dfx, dfy,
                                                random_state=1)

"""We can see what parameters are available in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)

 Once we know what hyperparameters we want to exmplore, we can automate the exploration of hyperparameter space by using grid search
"""

# import Grid Search
from sklearn.model_selection import GridSearchCV

# Set parameters to search over.
parameters = {'C':[0.01,0.1,1,10,100], 'gamma':[0.01,0.1,1,10]}
svc = SVC(kernel='rbf')                                                                            # Select Model
clf = GridSearchCV(svc, parameters)                                                         #
clf.fit(Xtrain, ytrain)

clf.best_params_

clf = make_pipeline(StandardScaler(), SVC(C=1000, gamma=100, kernel='rbf'))
clf.fit(Xtrain, ytrain)
y_model = clf.predict(Xtest)
f1_score(ytest, y_model, average='weighted')

"""First, we changed the model definitions which led to an accuracy of 1.0 which is evidence of over-fitting to counter that, we have changed the the random state after testing multiple variants we concluded that 777 once that's done we were able to get accuracy of 0.83. After doing some research on KNN algorithms, we determined that adding scalar function would increase the accuracy as the model, a proper segmentation happens with the scalar function in knn. Once that's added accuracy shot up to 0.988. Now while adding hyperparameters we tested euclidian and manhattan formula as metric and for weights we tested uniform and distance. After the test, we determined that n_neighbor=8, metric= manhattan, weights = distance which gave an accuracy rating of 0.92

# Assignment :  On Your Own

**You will create your first Machine Learning model.**

1. Setup Colab account
2. Use this notebook as a guide (available on Canvas)
2. Import some data
    * Try this first on something simple like Penguins or Irises.
    * (optional) Download a Cyber dataset and try with that one.
    * What issues did you run into? Can you solve them?
3. Get a working model running (k-NN, SVM, or one of the others)
4. Modify hyperparameters and see if you can improve upon initial performance.your results
    * Document your results
5. Submit your Jupyter Notebook
    * Don't worry if things aren't working. We will troubleshoot next class

*Note: You may work together on this work but each person must submit their own notebook.  If you work with someone else, you must indicate who you worked with*
"""